{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "70553c19-80d0-423e-864d-2c1eee764749",
        "_uuid": "ebc874e4c2aa865e1d7345eeb85aafd87e52ae35",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport time\nfrom itertools import combinations\nfrom collections import defaultdict\n\nimport numpy as np\nfrom random import sample\nfrom scipy.special import binom\n\nimport pandas as pd\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\n\nfrom xgboost import XGBClassifier\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nRNG_SEED = int(time.time())\nprint(\"Seed: %s\" % RNG_SEED)\noverwrite_models = True",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f7fd3fa0-8fdb-43bd-b250-f575fe920abb",
        "_uuid": "5d765a6c0aaf79894090c7792947a47610c1b5fa",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\n\n# train_df.info()\n# train_df.head()\n# test_df.info()\n\noutcome = train_df[\"Survived\"]\n# feature_df = train_df.drop([\"Cabin\", \"Survived\", \"PassengerId\", \"Name\", \"Ticket\"], axis=1)\nfeature_df = train_df.drop([\"Survived\", \"PassengerId\", \"Cabin\", \"Name\"], axis=1)\nfeature_df.fillna({\"Age\": train_df[\"Age\"].median()}, inplace=True)\nfeature_df.fillna({\"Embarked\": train_df[\"Embarked\"].mode()[0]}, inplace=True)\nfeature_df[\"FamilySize\"] = feature_df[\"SibSp\"] + feature_df[\"Parch\"]\nfeature_df.info()\n\n# test_df = test_df.drop([\"Cabin\", \"PassengerId\", \"Name\", \"Ticket\"], axis=1)\npassenger_ids = test_df[\"PassengerId\"]\ntest_df = test_df.drop([\"PassengerId\", \"Cabin\", \"Name\"], axis=1)\ntest_df.fillna({\"Age\": test_df[\"Age\"].median()}, inplace=True)\ntest_df.fillna({\"Fare\": test_df[\"Fare\"].median()}, inplace=True)\ntest_df[\"FamilySize\"] = test_df[\"SibSp\"] + test_df[\"Parch\"]\ntest_df.info()\n\ncategorical_vars_indices = np.where((feature_df.dtypes == object) | (feature_df.dtypes == bool))[0]\ncategorical_vars = feature_df.columns[categorical_vars_indices]\nle = LabelEncoder()\n\nfor var in categorical_vars:\n    data = pd.concat([feature_df.loc[:, var], test_df.loc[:, var]])\n    le = le.fit(data)\n    feature_df.loc[:, var] = le.transform(feature_df.loc[:, var])\n    test_df.loc[:, var] = le.transform(test_df.loc[:, var])\n    \nscaler = MinMaxScaler()\nfeature_df[:] = scaler.fit_transform(feature_df)\ntest_df[:] = scaler.fit_transform(test_df)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "700ba3b1cf466d18c2b75e20047770fb1810cce7",
        "trusted": false
      },
      "cell_type": "code",
      "source": "skf_cv = StratifiedKFold(5)\n# predetermined folds to be used for model stacking\nstack_folds = list(StratifiedKFold(5).split(feature_df, outcome))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "cec0d3f2-d937-44f3-ba69-c12d68f3cc15",
        "_uuid": "42914fdea367ca9dbeb62c1aaf530d228ddfc0f3",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def best_accuracy_threshold(proba_preds, truth, cuts=np.arange(0, 1, 0.01)):\n    acc = np.full(len(cuts), None)\n    for i, cut in enumerate(cuts):\n        cv_preds = proba_preds > cut\n        acc[i] = accuracy_score(truth, cv_preds)\n    best_index = np.argmax(acc)\n    fig, ax = plt.subplots()\n    ax.plot(cuts, acc)\n    ax.set_title(\"best proba cut = %s\" % acc[best_index])\n    plt.show()\n    return(cuts[best_index], acc[best_index])\n\ndef feature_combinations(features, n_features, n_comb):\n    for i in range(n_comb):\n        yield sample(features, n_features)\n\ndef subset_var_selection(model, param_grid, X, y, n_feature_list=None, \n                         n_feature_comb=10):\n    features = list(X.columns)\n    if n_feature_list is None:\n        n_feature_list = range(2, len(features) + 1)\n    \n    best_tuple = None\n    var_scores = defaultdict(list)\n    for n_features in n_feature_list:\n        \n        if type(n_feature_comb) is float:\n            # proportion of the total number of feature combinations\n            n_comb = n_feature_comb * binom(len(features), n_features)\n        elif type(n_feature_comb) is int:\n            n_comb = min(n_feature_comb, int(binom(len(features), n_features)))\n        else:\n            raise TypeError(\"n_feature_comb must be a float or an int\")\n            \n        for comb in feature_combinations(features, n_features, n_comb):\n            # print(comb)\n            gs = GridSearchCV(model, param_grid, cv=skf_cv, scoring=\"neg_log_loss\")\n            cv_opt = gs.fit(X.loc[:, comb], y)\n            # print(comb, cv_opt.best_score_)\n            if best_tuple is None or cv_opt.best_score_ > best_tuple[2]:\n                best_tuple = (comb, cv_opt.best_params_, cv_opt.best_score_)\n            \n            for var in comb:\n                var_scores[var].append(cv_opt.best_score_)\n                \n    var_avg_score = []\n    for var, scores in var_scores.items():\n        var_avg_score.append((var, np.mean(scores)))\n                \n    return best_tuple, var_avg_score\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "28147306-d79b-421f-b474-6cd4fb1a6476",
        "_uuid": "3d4d9d11edf0365c89a47f20f406ca757e073a36",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# variable selection + parameter tuning with cross-validation\n\"\"\"\nnb_param_grid = {\"alpha\": np.arange(1e-10, 2, 0.1)}\nbest_tuple, var_imp = subset_var_selection(MultinomialNB(), nb_param_grid, \n                                           feature_df, outcome, n_feature_comb=50)\nnb_best_vars, nb_best_params, nb_best_score = best_tuple\nprint(var_imp)\n\"\"\"\n\n# from a previous run of the code above, for the submission\nnb_best_vars = ['Pclass', 'Parch', 'Embarked', 'Fare', 'Ticket', 'FamilySize', 'Age', 'Sex']\nnb_best_params = {'alpha': 1e-10}\nnb_best_score = -0.590673933422132\n\nbest_nb = MultinomialNB(alpha=nb_best_params[\"alpha\"])\nprint(nb_best_vars)\n\n# Use the fold predictions to get the best cutoff on the \n# class probabilities. This probably introduces a slight \n# risk of overfitting since the cutoff is not computed on a per-fold \n# basis.\n# The (hard?) fold predictions will be used for model stacking\nnb_cv_proba_preds = cross_val_predict(best_nb, feature_df.loc[:, nb_best_vars], outcome,\n                                      cv=stack_folds, method=\"predict_proba\")\nnb_cv_proba_preds = np.array([elt[1] for elt in nb_cv_proba_preds])\nnb_best_cut, nb_best_acc = best_accuracy_threshold(nb_cv_proba_preds, outcome)\nnb_cv_preds = nb_cv_proba_preds > nb_best_cut\nprint(accuracy_score(outcome, nb_cv_preds))\n\n# the full model is used to predict the test set\nfull_nb_model = best_nb.fit(feature_df.loc[:, nb_best_vars], outcome)\nnb_test_proba_preds = full_nb_model.predict_proba(test_df.loc[:, nb_best_vars])\nnb_test_proba_preds = np.array([elt[1] for elt in nb_test_proba_preds])\nnb_test_preds = nb_test_proba_preds > nb_best_cut",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9de84acc-bcde-4097-8d70-d749202e18ea",
        "_uuid": "c938f164d60b9315228979ce031c7be4b6a7601d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "\"\"\"\n# parameter tuning\nxgb_reg_ratios = [0.1, 0.5, 0.9, 0.99]\nxgb = XGBClassifier(random_state=RNG_SEED)\nxgb_param_grid = {\"n_estimators\": [200, 500],\n                  \"max_depth\": [1, 2, 3],\n                  \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n                  \"reg_lambda\": xgb_reg_ratios,\n                  \"reg_alpha\": xgb_reg_ratios}\ngs_xgb = GridSearchCV(xgb, xgb_param_grid, cv=skf_cv, \n                      scoring=\"neg_log_loss\")\ncv_opt_xgb = gs_xgb.fit(feature_df, outcome)\ncv_opt_xgb_model = cv_opt_xgb.best_estimator_\n\nprint(cv_opt_xgb_model)\n\n# feature importances\nfig, ax = plt.subplots()\nax.bar(range(len(cv_opt_xgb_model.feature_importances_)), \n        cv_opt_xgb_model.feature_importances_)\nax.set_title(cv_opt_xgb.best_score_)\nplt.show()\n\"\"\"\n\n# from a previous run of the code above, for the submission\ncv_opt_xgb_model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n                       max_depth=3, min_child_weight=1, missing=None, n_estimators=200,\n                       n_jobs=1, nthread=None, objective='binary:logistic',\n                       random_state=RNG_SEED, reg_alpha=0.1, reg_lambda=0.5,\n                       scale_pos_weight=1, seed=None, silent=True, subsample=1)\n\n# The fold predictions will be used for model stacking\nxgb_cv_preds = cross_val_predict(cv_opt_xgb_model, feature_df, outcome,\n                                 cv=stack_folds, method=\"predict\")\nprint(accuracy_score(outcome, xgb_cv_preds))\n\n# the full model is used to predict the test set\nfull_xgb_model = cv_opt_xgb_model.fit(feature_df, outcome)\nxgb_test_preds = full_xgb_model.predict(test_df)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f6cd138a-cce2-4eca-a9ae-ac24258e9053",
        "_uuid": "5b2072d751fbc015ffc523739ef7f5380d26fc48",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# fold predictions of the base learners to be used for \n# training the meta model\n# stack_cv_preds = np.vstack([nb_cv_preds, xgb_cv_preds]).T\nstack_cv_preds = np.vstack([nb_cv_proba_preds, xgb_cv_preds]).T\n\n# meta model\nlr = LogisticRegression(random_state=RNG_SEED, max_iter=10000)\n\n# cross-validation (note: using the same stack folds) to assess \n# the accuracy of the meta model\nstack_cv_proba_preds = cross_val_predict(lr, stack_cv_preds, outcome,\n                                         cv=stack_folds, method=\"predict_proba\")\nstack_cv_proba_preds = np.array([elt[1] for elt in stack_cv_proba_preds])\nstack_best_cut, stack_best_acc = best_accuracy_threshold(stack_cv_proba_preds, outcome)\n# stack_cv_preds = stack_cv_proba_preds > stack_best_cut\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6cc4948a-ee21-48c7-ab98-3df8d2d68611",
        "_uuid": "bbb213c099a0f959d918d9c81f854c56642d87c5",
        "trusted": false
      },
      "cell_type": "code",
      "source": "lr = lr.fit(stack_cv_preds, outcome)\nprint(lr.coef_)\n# stack_test_preds = np.vstack([nb_test_preds, xgb_test_preds]).T\nstack_test_preds = np.vstack([nb_test_proba_preds, xgb_test_preds]).T\n\ntest_proba_preds = lr.predict_proba(stack_test_preds)\ntest_proba_preds = [elt[1] for elt in test_proba_preds]\ntest_preds = test_proba_preds > stack_best_cut\ntest_preds = test_preds.astype(int)\n\nsubmission = pd.DataFrame({\"PassengerId\": passenger_ids, \"Survived\": test_preds})\nsubmission.to_csv('model_stacking_nb_xgb_to_lr.csv', index=False)\n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}